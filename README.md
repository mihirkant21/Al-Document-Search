# ğŸ“„ AI Document Search (RAG Chatbot)

Chat with your PDF documents using an **AI-powered chatbot**.  
This project uses **Retrieval-Augmented Generation (RAG)** so the answers are based on your uploaded files, not just the modelâ€™s memory.

---

## âœ¨ Features
- ğŸ“‚ **Upload PDF documents** for ingestion  
- ğŸ” **Semantic search with embeddings** (finds meaning, not just keywords)  
- ğŸ’¬ **Ask natural questions** and get accurate, context-aware answers  
- ğŸ“‘ **Source citations** from your original documents  
- âš¡ Lightweight **Frontend (HTML, CSS, JS)** + **FastAPI backend**  
- ğŸ§  Powered by **Ollama LLM + LangChain**  
- ğŸ“¦ Vector database with **FAISS (local)**  

---

## ğŸ› ï¸ Tech Stack
**Frontend:** HTML, CSS, JavaScript  
**Backend:** FastAPI (Python)  
**AI Model:** Ollama (LLM) + LangChain (retrieval & QA chain)  
**Vector DB:** FAISS (default)  
**Deployment:** Docker (backend), Vercel/Static hosting (frontend)  

---

## âš™ï¸ How It Works
1. **Upload PDF** â†’ Extract text with LangChain loaders  
2. **Chunk text** â†’ Split into smaller sections for better retrieval  
3. **Embed chunks** â†’ Convert into vectors using Ollama embeddings  
4. **Store vectors** â†’ Save in **FAISS** database  
5. **Ask a question** â†’ Query is embedded and compared to stored vectors  
6. **Retrieve top matches** â†’ Most relevant document chunks are selected  
7. **Generate answer** â†’ Ollama LLM forms a response using retrieved chunks  
8. **Return results** â†’ Answer is displayed in the chatbot UI  

---

## ğŸ“‚ Project Structure
